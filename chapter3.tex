\chapter{Теория}\label{chap3}

\section{Основные предположения}\label{2sec:problem-formulation}

Пусть $\mathbb{I}_{[a,b]}$ -- множество целых чисел на отрезке $[a,b]$.
Для вектора $x$ и положительно определённой матрицы $P=P^T>0$ запишем $\|x\|_P=\sqrt{x^TPx}$.
\newline
Далее определим максимальное и минимальное собственные значения матрицы P
$\lambda_{\min}(P)$ и $\lambda_{\max}(P)$.

\indent Для матриц $P_1=P_1^T, P_2=P^T_2$ запишем, 	
\begin{displaymath}
	\lambda_{\min}(P_1,P_2)=\min\{\lambda_{\min}(P_1),\lambda_{\min}(P_2)\},
\end{displaymath}
\begin{displaymath}
	\lambda_{\max}(P_1,P_2)=\max\{\lambda_{\max}(P_1),\lambda_{\max}(P_2)\}.
\end{displaymath}
 Также $\|x\|_2,\|x\|_1$, $\|x\|_\infty$ -- Евклидовы, $\ell_1$ и $\ell_\infty$ нормы $x$, соответственно.
\newline
Для $\delta > 0$, мы определим $\mathbb{B}_\delta=\{x \in \mathbb{R}^n \, | \, \|x\|_2 \leq\delta\}$.


\indent Из последовательности $\{x_k\}^{N-1}_{k=0}$ составим матрицу Ганкеля
\begin{displaymath}
H_L(x)=
\begin{bmatrix}
	x_0 && x_1 && \dots && x_{N-L} \\
	x_1 && x_2 && \dots && x_{N-L+1} \\
	\vdots && && \ddots && \vdots \\
	x_{L-1} && x_L && \dots && x_{N-1}
\end{bmatrix},
\end{displaymath}

\begin{displaymath}
x_{[a,b]}=
\begin{bmatrix}
	x_a \\ \vdots \\ x_b
\end{bmatrix}
\end{displaymath}

\begin{Def}
	$\{x_k\}_{k=0}^{N-1}$ с $x_k \in \mathbb{R}^n$ постоянно возбуждающая порядка L, если $\rank (H_L(x))=nL$.
\end{Def}
Цель паботы -- управление неизвестной линейной стационарной системой $G$ c порядком $n$, с $m$ входами и $p$ выходами. 

\begin{Def}
	 Последовательность $\{u_k,y_k\}^{N-1}_{k=0}$ -- траектория линейной стационарной системы $G$, если существуют начальное состояние $\overline{x} \in \mathbb{R}^n$, а также соответсвующая траектория $\{x_k\}^N_{k=0}$ такая, что 
	 \begin{displaymath}
	 	x_{k+1}=Ax_{k+1}+Bu_k; \; x_0=\overline{x},
	 \end{displaymath}
	 \begin{displaymath}
	  	y_k=Cx_k+Du_k, \; k=0,\dots,N-1,
	 \end{displaymath}
	$(A,B,C,D)$ -- минимальные реализация $G$.
\end{Def}

\begin{theorem}\label{trajectoryTheorem}
	Предположим, что $\{u^d_k,y^d_k\}^{N-1}_{k=0}$ -- траектория линейной стационарной системы $G$, где $u$ -- постоянно возбуждающее управление порядка $L+n$.
\newline
Тогда $\{\overline{u}_k,\overline{y}_k\}^{L-1}_{k=0}$ -- траектория $G$, тогда и только тогда, когда $\exists \alpha \in \mathbb{R}^{N-L+1}$ такое, что
	\begin{equation}\label{formuleOfTrajectoryTheorem}
		\begin{bmatrix}
			H_L(u^d) \\
			H_L(y^d)
		\end{bmatrix} \alpha = 
		\begin{bmatrix}
			\overline{u} \\
			\overline{y}
		\end{bmatrix}.
	\end{equation}
\end{theorem}

\begin{Def}\label{defTrajectory}
Пара $(u^s,y^s) \in \mathbb{R}^{m+p}$ -- положение равновесия линейной стационарной системой $G$, если последовательность $\{\overline{u}_k,\overline{y}_k\}^{n-1}_{k=0}$ с $(\overline{u}_k,\overline{y}_k) = (u^s,y^s) \; \forall k \in \mathbb{I}{[0,n-1]} $ -- траектория $G$.
\end{Def}

	Для равновесия $(u^s,y^s)$ мы определим $u^s_n, y^s_n$ как столбец векторов содержащий $n$ раз $u^s$ и $y^s$, соответственно. Предположим, что система подчиняется ограничениям,
$u_t \in \mathbb{U} \subseteq \mathbb{R}^m, y_t \in \mathbb{Y} \subseteq \mathbb{R}^p \; \forall t \geq 0$, и предположим, что $(u^s, y^s) \in int(\mathbb{U} \times \mathbb{Y})$. $\{u^d_k,y^d_k\}^{N-1}_{k=0}$ -- априори измеряемые траектории длинной $N$, использующиеся в (\ref{formuleOfTrajectoryTheorem}). Прогнозируемые входные и выходные траектории в момент времени $t$ в течение некоторого горизонта прогнозирования $L$ записываются как $\{\overline{u}_k(t),\overline{y}_k(t)\}^{L-1}_{k=-n}$.
\parskip
\parindent Обратим внимание, что индексы времени начинаются с $k=-n$, так как последние $n$ входов и выходов будут использоваться для вызова уникального начального состояния в момент времени $t$. Кроме того, вход с обратной связью, состояние в некоторой минимальной реализации и выход в момент времени $t$ обозначаются как $u_t,x_t, y_t$, соответственно.

\section{Задача с терминальными ограничениями-равенствами}\label{2sec:xxx}
	В этом пункте рассмотрим простое терминальное ограничение, которое может быть включено непосредственно в структуру управления данными MPC.
\begin{equation}\label{problem2a}
		J^*_L(u_{[t-n,t-1]},y_{[t-n,t-1]}) = \underset{\substack{\alpha(t)\ \overline{u}(t),\overline{y}(t)}} \min \sum^{L-1}_{k=0}\ell(\overline{u}_k(t),\overline{y}_k(t))
\end{equation}
\begin{equation}\label{problem2b}
	\begin{bmatrix}
		\overline{u}_{[-n,-L-1]}(t) \\
		\overline{y}_{[-n,-L-1]}(t)
	\end{bmatrix} = 
	\begin{bmatrix}
		H_{L+n}(u^d) \\ 
		H_{L+n}(y^d)
	\end{bmatrix}\alpha(t),	
\end{equation}
\begin{equation}\label{problem2c}
	\begin{bmatrix}
		\overline{u}_{[-n,-1]}(t) \\ 
		\overline{y}_{[-n,-1]}(t) 
	\end{bmatrix} = 
	\begin{bmatrix}
		u_{[t-n,t-1]} \\
		y_{[t-n,t-1]}
	\end{bmatrix},
\end{equation}
\begin{equation}\label{problem2d}
	\begin{bmatrix}
		\overline{u}_{[L-n,L-1]}(t) \\ 
		\overline{y}_{[L-n,L-1]}(t) 
	\end{bmatrix} = 
	\begin{bmatrix}
		u_{n}^s \\
		y_{n}^s
	\end{bmatrix},
\end{equation}
\begin{equation}\label{problem2e}
	\overline{u}_k(t) \in \mathbb{U}, \overline{y}_k(t) \in \mathbb{Y}, k \in \mathbb{I}_{[0,L-1]}.
\end{equation}

Терминальное ограничение-равенство (\ref{problem2d}) подразумевает, что $\overline{x}_L(t)$, который является внутренним состоянием, предсказанным на $L$ шагов вперед, соответствующей предсказанной траекторией, выравнивается с постоянным состоянием $x^s$, соответствующим $(u^s, y^s)$, то есть $\overline{x}_L(t)=x^s$ в любой минимальной реализации. В то время как задача требует, чтобы $(u^s, y^s)$ было равновесием неизвестной системы по определению (\ref{defTrajectory}), это требование может быть отброшено, когда $(u^s, y^s)$ заменено искусственным равновесием, которое также оптимизируется онлайн. Расширение представленной схемы MPC до такой настройки является предметом будущей работы. Как и в стандартном MPC, задача решена в виде отступающего горизонта, который обобщен в алгоритме (\ref{Alg1}).

\begin{algorithm}\label{Alg1} (Схема управления на основе MPC)
	\begin{enumerate}
		\item В момент времени $t$ взять прошлые $n$ измерений $u_{[t-n,t-1]}, y_{[t-n,t-1]}$  и решить задачу.
		\item Взять за управление $u_t=\overline{u}_0^*(t)$
		\item Установить $t=t+1$ и вернуться к пункту 1).
	\end{enumerate}
\end{algorithm}

\section{Робастная схема MPC с терминальными ограничениями}

На практике выходной сигнал неизвестной системы G обычно является неточным. Это означает, что сложенные матрицы Ганкеля, зависящие от данных, в \ref{formuleOfTrajectoryTheorem} не покрывают пространство траекторий системы точно и, следовательно, выходные траектории не могут быть точно предсказаны. Более того, измерения выходного сигнала с зашумлением входят в начальные условия в задаче (\ref{problem2a}-\ref{problem2e}), что еще больше ухудшает точность прогноза. 

В данном разделе будет предполагаться, что выходные сигналы с ограниченным аддитивным шумом находятся в изначально доступных данных $\widetilde{y}^d_k=y^d_k+\varepsilon^d_k$ и в измерениях $\widetilde{y}_k=y_k+\varepsilon_k$. Мы не делаем никаких предположений о природе шума, но требуем, чтобы он был ограничен как $\|\varepsilon^d_k\|_\infty\leq \overline{\varepsilon}$ и $\|\varepsilon_k\|_\infty\leq \overline{\varepsilon}$ для некоторого $\overline{\varepsilon}$. Ключевой идеей для учета зашумленных измерений является ослабление ограничения равенства (\ref{problem2b}). При зашумленной начальной траектории $(u_{[t-n,t-1]},\widetilde{y}_{[t-n,t-1]})$ длины $n$, предлагается следующая надежная модификация (\ref{problem2a}-\ref{problem2e}).

\begin{equation}\label{problem3a}
		J^*_L(u_{[t-n,t-1]},\widetilde{y}_{[t-n,t-1]}) = \underset{\substack{\alpha(t),\overline{u}(t),\overline{y}(t), \sigma(t)}} \min \sum^{L-1}_{k=0}\ell(\overline{u}_k(t),\overline{y}_k(t)) + \lambda_\alpha \overline{\varepsilon}\|\alpha(t)\|^2_2 + \lambda_\sigma \|\sigma(t)\|^2_2
\end{equation}
\begin{equation}\label{problem3b}
	\begin{bmatrix}
		\overline{u}(t)\\
		\overline{y}(t) + \sigma(t)
	\end{bmatrix} = 
	\begin{bmatrix}
		H_{L+n}(u^d) \\ 
		H_{L+n}(\widetilde{y}^d)
	\end{bmatrix}\alpha(t),	
\end{equation}
\begin{equation}\label{problem3c}
	\begin{bmatrix}
		\overline{u}_{[-n,-1]}(t) \\ 
		\overline{y}_{[-n,-1]}(t) 
	\end{bmatrix} = 
	\begin{bmatrix}
		u_{[t-n,t-1]} \\
		y_{[t-n,t-1]}
	\end{bmatrix},
\end{equation}
\begin{equation}\label{problem3d}
	\begin{bmatrix}
		\overline{u}_{[L-n,L-1]}(t) \\ 
		\overline{y}_{[L-n,L-1]}(t) 
	\end{bmatrix} = 
	\begin{bmatrix}
		u_{n}^s \\
		y_{n}^s
	\end{bmatrix}, \overline{u}_k \in \mathbb{U},
\end{equation}
\begin{equation}\label{problem3e}
	\|\sigma_k(t)\|_\infty \leq \overline{\varepsilon}(1+ \| \alpha(t) \|_1), k \in \mathbb{I}_{[0,L-1]}.
\end{equation}
По сравнению с задачей (\ref{problem2a}-\ref{problem2e}) траектория выходных данных $\widetilde{y}^d$ и начальный выходной сигнал $\widetilde{y}_{[t-n,t-1]}$, полученные из онлайн измерений, были заменены их зашумленными аналогами.
Также были добавлены следующие элементы:
\begin{enumerate}
	\item Вспомогательная переменная $\sigma$ для олнайн измерений $\widetilde{y}_{[t-n,t-1]}$ и для зашумленных данных $\widetilde{y}^d$, используемых для предсказаний.
	\item Квадратичная норма для $\sigma$ и $\alpha$ с весами $\lambda_\alpha \overline{\varepsilon}, \lambda_\sigma > 0$, норма $\alpha$ зависит от уровня шума.
\end{enumerate}

\section{n-Шаговая схема управления на основе MPC}
В этой главе мы рассматриваем управление по замкнутому контуру, полученное в результате применения (\ref{problem3a}-\ref{problem3e}) в $n$-шаговой схеме MPC. Чтобы быть более точным, мы рассматриваем сценарий, в котором сразу после решения (\ref{problem3a}-\ref{problem3e}) первые $n$ вычисленных входных сигналов применяются к системе. После этого горизонт сдвигается на $n$ шагов, прежде чем вся схема повторяется.

\begin{algorithm}\label{Alg2}(n-Шаговая схема управления на основе MPC)
	\begin{enumerate}
		\item В момент времени $t$ взять прошлые $n$ измерений $\{u_{[t-n,t-1]}, \widetilde{y}_{[t-n,t-1]}\}$  и решить задачу (\ref{problem3a})-(\ref{problem3e}).
		\item Взять за управление $u_{[t,t+n-1]}=\overline{u}_{[t,n-1]}^*(t)$
		\item Установить $t=t+n$ и вернуться к пункту 1).
	\end{enumerate}
\end{algorithm}

Задача (\ref{problem3a}-\ref{problem3e}) - это строго выпуклая квадратичная задача и она может быть эффективно решена. Однако ограничение на $\sigma$ в (\ref{problem3e}) невыпукло из-за зависимости правой части от $\|\alpha(t)\|_1$, что затрудняет эффективную реализацию (\ref{problem3a}-\ref{problem3e}).(\ref{problem3e}) требуется для доказательства рекурсивной выполнимости и практической экспоненциальной устойчивости. Однако его можно заменить (выпуклым) ограничением $\|\sigma_k(t)\|_\infty\leq c \cdot \overline{\varepsilon}$ для достаточно большой постоянной $c > 0$ $с$ сохранением тех же теоретических гарантий. Как правило, больший выбор $c$ увеличивает область притяжения, но также увеличивает размер экспоненциально устойчивого множества, к которому сходится замкнутый контур. Кроме того, ограничение (\ref{problem3e}) может быть реализовано неявно, выбирая $\lambda_\sigma$ достаточно большим. В примерах моделирования было замечено, что ограничение (\ref{problem3e}) обычно выполняется (для достаточно большого выбора $\lambda_\sigma$), не применяя его явно в задаче оптимизации, и, таким образом, в большинстве случаев им можно пренебречь при онлайн-оптимизации.
