\chapter{Теория}\label{chap3}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Теория управления по прогнозирующей модели}\label{1sec:MPC}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


Главная идея MPC \cite{Mayne} -- использование математической модели управляемого процесса в пространстве состояний для предсказания и оптимизации будущего поведения системы.
Рассмотрим задачу стабилизации нелинейной системы 
\begin{equation}\label{x(t+1)}
	x(t+1)=f(x(t),u(t)),\, t=0,1,\dots,
\end{equation}
где 
\newline
	$x=x(t) \in \mathbb{R}^n$ -- состояние системы в момент времени $t$;\newline
	$u=u(t) \in \mathbb{R}^r$ -- значение управляющего воздействия в момент времени $t$;
$f: \mathbb{R}^n \times \mathbb{R}^r \rightarrow \mathbb{R}^n$ -- заданная функция.
\par Пусть $f(0,0)=0$, следовательно точка равновесия системы находится в начале координат, и при тривиальном управлении $u\equiv0$ система остаётся в состоянии покоя.
\par При заданном управлении $u(\cdot)$, траектория системы (\ref{x(t+1)}) обозначается как $x(t|0,z,u(\cdot)), \, t=0,1,\dots$, где начальное состояние системы в момент времени $t=0$ задаётся условием $x(0)=z$.
\par Управление $u(\cdot)$ будем выбирать так, чтобы максимально приблизить траектории $x(t|0,x_0,u(\cdot)), \, t=0,1,\dots,N,$ к началу координат.

\begin{Def}
	Стоимость этапа -- функция $l(x(t),u(t))$ вдоль траектории $x(\cdot)$ и управления $u(\cdot)$, с помощью которой для всех моментов времени $t=0,1,\dots$ оценивается качество выбранного урпавления $u(\cdot)$.
\end{Def}

Чаще всего стоимость этапа $l$ выбирается следующим образом:
\begin{enumerate}
	\item Взвешенная сумма расстояний до начала координат:
	\begin{center}
		$l(x,u)=\parallel x\parallel ^2+\lambda\parallel u\parallel ^2, \quad
\lambda \geq 0$ -- параметр, $\parallel \cdot \parallel$ -- евклидова норма.
	\end{center}
	\item Квадратичные функции
	\begin{center}
		$l(x,u)=x'Qx+u'Ru$
	\end{center}
$R,Q>0$ -- положительно-определённые матрицы.
\end{enumerate}
\bigskip

Таким образом задача оптимального управления состоит в минимизации функционала, где минимум ищем вдоль траекторий $x(t|0,x^*(\tau),u(\cdot)), t=0,1,\dots, N-1$, системы (\ref{x(t+1)}) с начальным состоянием, совпадающим с текущим состоянием объекта $x(0)=x^*(\tau)$ и при некоторых ограничениях:
\begin{equation}\label{J(x^*(tau))}
	J(x^*(\tau))=\min_{u(\cdot)}\sum_{t=0}^{N-1} l(x(t|0,x^*(\tau),u(\cdot)),u(t)).
\end{equation}

Ограничения для задачи (\ref{J(x^*(tau))}) состояит из двух групп:
\begin{enumerate}
 \item Физические ограничения системы (например, неотрицательность переменных, максимальное ограничение на управляющее воздействие и другие);
 \item Ограничения, накладываемые алгоритмом MPC (например, терминальное ограничение вида $x(N)=0$ или принадлежность $x(N)$ множеству $X_f$).
\end{enumerate}

Обозначим оптимальное программное решение задачи (\ref{J(x^*(tau))}) через $u^0(\cdot|x^*(\tau))$. Для построения обратных связей будем считать, что на объект
управления подано первое значение оптимальной программы 
\begin{center}
	$\mu(x^*(\tau))=u^0(0|x^*(\tau)).$
\end{center}

Далее в момент времени $\tau + 1$ процесс повторяется для состояния
$x^*(\tau+1)$. Тогда в этот момент времени решается задача о минимизации следующего функционала:
\begin{center}
	$
	J(x^*(\tau+1))=\underset{{u(\cdot)}}\min\sum_{t=0}^{N-1} l(x(t|0,x^*(\tau+1),u(\cdot)),u(t)).$
\end{center}


При этом будет получено очередное значение обратной связи:
\begin{displaymath}
	\mu(x^*(\tau+1))=u^0(0|x^*(\tau+1)).
\end{displaymath}
После процесс повторяется при $\tau + 2, \tau + 3$ и так далее.
Таким образом, алгоритм управления по прогнозирующей модели, в каждый момент времени $\tau = 0,1,\dots$ состоит из следующих шагов:
\begin{enumerate}
	 \item Измеряется текущее состояние $x^*(\tau)$
	 \item Находится оптимальное программное решение $u^0(t|x^*(\tau))$ задачи (\ref{J(x^*(tau))}).
	 \item Подаётся на объект системы управляющее воздействие 
	\begin{center}
		 $\mu^*(\tau)  \equiv \mu(x^*(\tau))=\mu^0(0|x^*(\tau))$.
	\end{center}		 
\end{enumerate}

\indent Идея упрваления по прогнозирущей модели заключается в оптимизации будущего поведения системы в каждый момент времени, нахождение оптимального управления и его использования в качестве значений обратной связи для следующего момента времени.



\section{Основные предположения}\label{2sec:problem-formulation}

Пусть $\mathbb{I}_{[a,b]}$ -- множество целых чисел на отрезке $[a,b]$.
Для вектора $x$ и положительно определённой матрицы $P=P^T>0$ запишем $\|x\|_P=\sqrt{x^TPx}$.
\newline
Далее определим максимальное и минимальное собственные значения матрицы P
$\lambda_{\min}(P)$ и $\lambda_{\max}(P)$.

\indent Для матриц $P_1=P_1^T, P_2=P^T_2$ запишем, 	
\begin{displaymath}
	\lambda_{\min}(P_1,P_2)=\min\{\lambda_{\min}(P_1),\lambda_{\min}(P_2)\},
\end{displaymath}
\begin{displaymath}
	\lambda_{\max}(P_1,P_2)=\max\{\lambda_{\max}(P_1),\lambda_{\max}(P_2)\}.
\end{displaymath}
 Также $\|x\|_2,\|x\|_1$, $\|x\|_\infty$ -- Евклидовы, $\ell_1$ и $\ell_\infty$ нормы $x$, соответственно.
\newline
Для $\delta > 0$, мы определим $\mathbb{B}_\delta=\{x \in \mathbb{R}^n \, | \, \|x\|_2 \leq\delta\}$.


\indent Из последовательности $\{x_k\}^{N-1}_{k=0}$ составим матрицу Ганкеля
\begin{displaymath}
H_L(x)=
\begin{bmatrix}
	x_0 && x_1 && \dots && x_{N-L} \\
	x_1 && x_2 && \dots && x_{N-L+1} \\
	\vdots && && \ddots && \vdots \\
	x_{L-1} && x_L && \dots && x_{N-1}
\end{bmatrix},
\end{displaymath}

\begin{displaymath}
x_{[a,b]}=
\begin{bmatrix}
	x_a \\ \vdots \\ x_b
\end{bmatrix}
\end{displaymath}

\begin{Def}
	$\{x_k\}_{k=0}^{N-1}$ с $x_k \in \mathbb{R}^n$ постоянно возбуждающая порядка L, если $\rank (H_L(x))=nL$.
\end{Def}
Цель работы -- управление неизвестной линейной стационарной системой $G$ c порядком $n$, с $m$ входами и $p$ выходами. 

\begin{Def}
	 Последовательность $\{u_k,y_k\}^{N-1}_{k=0}$ -- траектория линейной стационарной системы $G$, если существуют начальное состояние $\overline{x} \in \mathbb{R}^n$, а также соответсвующая траектория $\{x_k\}^N_{k=0}$ такая, что 
	 \begin{displaymath}
	 	x_{k+1}=Ax_{k+1}+Bu_k; \; x_0=\overline{x},
	 \end{displaymath}
	 \begin{displaymath}
	  	y_k=Cx_k+Du_k, \; k=0,\dots,N-1,
	 \end{displaymath}
	$(A,B,C,D)$ -- минимальные реализация $G$.
\end{Def}

\begin{theorem}\label{trajectoryTheorem}
	Предположим, что $\{u^d_k,y^d_k\}^{N-1}_{k=0}$ -- траектория линейной стационарной системы $G$, где $u$ -- постоянно возбуждающее управление порядка $L+n$.
\newline
Тогда $\{\overline{u}_k,\overline{y}_k\}^{L-1}_{k=0}$ -- траектория $G$, тогда и только тогда, когда $\exists \alpha \in \mathbb{R}^{N-L+1}$ такое, что
	\begin{equation}\label{formuleOfTrajectoryTheorem}
		\begin{bmatrix}
			H_L(u^d) \\
			H_L(y^d)
		\end{bmatrix} \alpha = 
		\begin{bmatrix}
			\overline{u} \\
			\overline{y}
		\end{bmatrix}.
	\end{equation}
\end{theorem}

\begin{Def}\label{defTrajectory}
Пара $(u^s,y^s) \in \mathbb{R}^{m+p}$ -- положение равновесия линейной стационарной системой $G$, если последовательность $\{\overline{u}_k,\overline{y}_k\}^{n-1}_{k=0}$ с $(\overline{u}_k,\overline{y}_k) = (u^s,y^s) \; \forall k \in \mathbb{I}{[0,n-1]} $ -- траектория $G$.
\end{Def}

	Для равновесия $(u^s,y^s)$ мы определим $u^s_n, y^s_n$ как столбец векторов содержащий $n$ раз $u^s$ и $y^s$, соответственно. Предположим, что система подчиняется ограничениям,
$u_t \in \mathbb{U} \subseteq \mathbb{R}^m, y_t \in \mathbb{Y} \subseteq \mathbb{R}^p \; \forall t \geq 0$, и предположим, что $(u^s, y^s) \in int(\mathbb{U} \times \mathbb{Y})$. $\{u^d_k,y^d_k\}^{N-1}_{k=0}$ -- априори измеряемые траектории длинной $N$, использующиеся в (\ref{formuleOfTrajectoryTheorem}). Прогнозируемые входные и выходные траектории в момент времени $t$ в течение некоторого горизонта прогнозирования $L$ записываются как $\{\overline{u}_k(t),\overline{y}_k(t)\}^{L-1}_{k=-n}$.
\parskip
\parindent Обратим внимание, что индексы времени начинаются с $k=-n$, так как последние $n$ входов и выходов будут использоваться для вызова уникального начального состояния в момент времени $t$. Кроме того, вход с обратной связью, состояние в некоторой минимальной реализации и выход в момент времени $t$ обозначаются как $u_t,x_t, y_t$, соответственно.

\section{Задача с терминальными ограничениями-равенствами}\label{2sec:xxx}
	В этом пункте рассмотрим простое терминальное ограничение, которое может быть включено непосредственно в структуру управления данными MPC.
\begin{equation}\label{problem2a}
		J^*_L(u_{[t-n,t-1]},y_{[t-n,t-1]}) = \underset{\substack{\alpha(t)\ \overline{u}(t),\overline{y}(t)}} \min \sum^{L-1}_{k=0}\ell(\overline{u}_k(t),\overline{y}_k(t))
\end{equation}
\begin{equation}\label{problem2b}
	\begin{bmatrix}
		\overline{u}_{[-n,-L-1]}(t) \\
		\overline{y}_{[-n,-L-1]}(t)
	\end{bmatrix} = 
	\begin{bmatrix}
		H_{L+n}(u^d) \\ 
		H_{L+n}(y^d)
	\end{bmatrix}\alpha(t),	
\end{equation}
\begin{equation}\label{problem2c}
	\begin{bmatrix}
		\overline{u}_{[-n,-1]}(t) \\ 
		\overline{y}_{[-n,-1]}(t) 
	\end{bmatrix} = 
	\begin{bmatrix}
		u_{[t-n,t-1]} \\
		y_{[t-n,t-1]}
	\end{bmatrix},
\end{equation}
\begin{equation}\label{problem2d}
	\begin{bmatrix}
		\overline{u}_{[L-n,L-1]}(t) \\ 
		\overline{y}_{[L-n,L-1]}(t) 
	\end{bmatrix} = 
	\begin{bmatrix}
		u_{n}^s \\
		y_{n}^s
	\end{bmatrix},
\end{equation}
\begin{equation}\label{problem2e}
	\overline{u}_k(t) \in \mathbb{U}, \overline{y}_k(t) \in \mathbb{Y}, k \in \mathbb{I}_{[0,L-1]}.
\end{equation}

Терминальное ограничение-равенство (\ref{problem2d}) подразумевает, что $\overline{x}_L(t)$, который является внутренним состоянием, предсказанным на $L$ шагов вперед, соответствующей предсказанной траекторией, выравнивается с постоянным состоянием $x^s$, соответствующим $(u^s, y^s)$, то есть $\overline{x}_L(t)=x^s$ в любой минимальной реализации. В то время как задача требует, чтобы $(u^s, y^s)$ было равновесием неизвестной системы по определению (\ref{defTrajectory}), это требование может быть отброшено, когда $(u^s, y^s)$ заменено искусственным равновесием, которое также оптимизируется онлайн. Расширение представленной схемы MPC до такой настройки является предметом будущей работы. Как и в стандартном MPC, задача решена в виде отступающего горизонта, который обобщен в алгоритме (\ref{Alg1}).

\begin{algorithm}\label{Alg1} (Схема управления на основе MPC)
	\begin{enumerate}
		\item В момент времени $t$ взять прошлые $n$ измерений $u_{[t-n,t-1]}, y_{[t-n,t-1]}$  и решить задачу.
		\item Взять за управление $u_t=\overline{u}_0^*(t)$
		\item Установить $t=t+1$ и вернуться к пункту 1).
	\end{enumerate}
\end{algorithm}

\section{Робастная схема MPC с терминальными ограничениями}

На практике выходной сигнал неизвестной системы G обычно является неточным. Это означает, что сложенные матрицы Ганкеля, зависящие от данных, в \ref{formuleOfTrajectoryTheorem} не покрывают пространство траекторий системы точно и, следовательно, выходные траектории не могут быть точно предсказаны. Более того, измерения выходного сигнала с зашумлением входят в начальные условия в задаче (\ref{problem2a}-\ref{problem2e}), что еще больше ухудшает точность прогноза. 

В данном разделе будет предполагаться, что выходные сигналы с ограниченным аддитивным шумом находятся в изначально доступных данных $\widetilde{y}^d_k=y^d_k+\varepsilon^d_k$ и в измерениях $\widetilde{y}_k=y_k+\varepsilon_k$. Мы не делаем никаких предположений о природе шума, но требуем, чтобы он был ограничен как $\|\varepsilon^d_k\|_\infty\leq \overline{\varepsilon}$ и $\|\varepsilon_k\|_\infty\leq \overline{\varepsilon}$ для некоторого $\overline{\varepsilon}$. Ключевой идеей для учета зашумленных измерений является ослабление ограничения равенства (\ref{problem2b}). При зашумленной начальной траектории $(u_{[t-n,t-1]},\widetilde{y}_{[t-n,t-1]})$ длины $n$, предлагается следующая надежная модификация (\ref{problem2a}-\ref{problem2e}).

\begin{equation}\label{problem3a}
		J^*_L(u_{[t-n,t-1]},\widetilde{y}_{[t-n,t-1]}) = \underset{\substack{\alpha(t),\overline{u}(t),\overline{y}(t), \sigma(t)}} \min \sum^{L-1}_{k=0}\ell(\overline{u}_k(t),\overline{y}_k(t)) + \lambda_\alpha \overline{\varepsilon}\|\alpha(t)\|^2_2 + \lambda_\sigma \|\sigma(t)\|^2_2
\end{equation}
\begin{equation}\label{problem3b}
	\begin{bmatrix}
		\overline{u}(t)\\
		\overline{y}(t) + \sigma(t)
	\end{bmatrix} = 
	\begin{bmatrix}
		H_{L+n}(u^d) \\ 
		H_{L+n}(\widetilde{y}^d)
	\end{bmatrix}\alpha(t),	
\end{equation}
\begin{equation}\label{problem3c}
	\begin{bmatrix}
		\overline{u}_{[-n,-1]}(t) \\ 
		\overline{y}_{[-n,-1]}(t) 
	\end{bmatrix} = 
	\begin{bmatrix}
		u_{[t-n,t-1]} \\
		y_{[t-n,t-1]}
	\end{bmatrix},
\end{equation}
\begin{equation}\label{problem3d}
	\begin{bmatrix}
		\overline{u}_{[L-n,L-1]}(t) \\ 
		\overline{y}_{[L-n,L-1]}(t) 
	\end{bmatrix} = 
	\begin{bmatrix}
		u_{n}^s \\
		y_{n}^s
	\end{bmatrix}, \overline{u}_k \in \mathbb{U},
\end{equation}
\begin{equation}\label{problem3e}
	\|\sigma_k(t)\|_\infty \leq \overline{\varepsilon}(1+ \| \alpha(t) \|_1), k \in \mathbb{I}_{[0,L-1]}.
\end{equation}
По сравнению с задачей (\ref{problem2a}-\ref{problem2e}) траектория выходных данных $\widetilde{y}^d$ и начальный выходной сигнал $\widetilde{y}_{[t-n,t-1]}$, полученные из онлайн измерений, были заменены их зашумленными аналогами.
Также были добавлены следующие элементы:
\begin{enumerate}
	\item Вспомогательная переменная $\sigma$ для олнайн измерений $\widetilde{y}_{[t-n,t-1]}$ и для зашумленных данных $\widetilde{y}^d$, используемых для предсказаний.
	\item Квадратичная норма для $\sigma$ и $\alpha$ с весами $\lambda_\alpha \overline{\varepsilon}, \lambda_\sigma > 0$, норма $\alpha$ зависит от уровня шума.
\end{enumerate}

\section{n-Шаговая схема управления на основе MPC}
В этой главе мы рассматриваем управление по замкнутому контуру, полученное в результате применения (\ref{problem3a}-\ref{problem3e}) в $n$-шаговой схеме MPC. Чтобы быть более точным, мы рассматриваем сценарий, в котором сразу после решения (\ref{problem3a}-\ref{problem3e}) первые $n$ вычисленных входных сигналов применяются к системе. После этого горизонт сдвигается на $n$ шагов, прежде чем вся схема повторяется.

\begin{algorithm}\label{Alg2}(n-Шаговая схема управления на основе MPC)
	\begin{enumerate}
		\item В момент времени $t$ взять прошлые $n$ измерений $\{u_{[t-n,t-1]}, \widetilde{y}_{[t-n,t-1]}\}$  и решить задачу (\ref{problem3a})-(\ref{problem3e}).
		\item Взять за управление $u_{[t,t+n-1]}=\overline{u}_{[t,n-1]}^*(t)$
		\item Установить $t=t+n$ и вернуться к пункту 1).
	\end{enumerate}
\end{algorithm}

Задача (\ref{problem3a}-\ref{problem3e}) - это строго выпуклая квадратичная задача и она может быть эффективно решена. Однако ограничение на $\sigma$ в (\ref{problem3e}) невыпукло из-за зависимости правой части от $\|\alpha(t)\|_1$, что затрудняет эффективную реализацию (\ref{problem3a}-\ref{problem3e}).(\ref{problem3e}) требуется для доказательства рекурсивной выполнимости и практической экспоненциальной устойчивости. Однако его можно заменить (выпуклым) ограничением $\|\sigma_k(t)\|_\infty\leq c \cdot \overline{\varepsilon}$ для достаточно большой постоянной $c > 0$ $с$ сохранением тех же теоретических гарантий. Как правило, больший выбор $c$ увеличивает область притяжения, но также увеличивает размер экспоненциально устойчивого множества, к которому сходится замкнутый контур. Кроме того, ограничение (\ref{problem3e}) может быть реализовано неявно, выбирая $\lambda_\sigma$ достаточно большим. В примерах моделирования было замечено, что ограничение (\ref{problem3e}) обычно выполняется (для достаточно большого выбора $\lambda_\sigma$), не применяя его явно в задаче оптимизации, и, таким образом, в большинстве случаев им можно пренебречь при онлайн-оптимизации.
